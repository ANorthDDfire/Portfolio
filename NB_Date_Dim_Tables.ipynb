{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d706d-72e4-496d-86de-275ba48a3114",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "%pip install govuk-bank-holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8757caf3-7d69-4d67-8fd4-58fdda80d82f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from deltalake import write_deltalake\n",
    "from govuk_bank_holidays.bank_holidays import BankHolidays\n",
    "from notebookutils import credentials\n",
    "\n",
    "# Fetch bank holidays data\n",
    "bank_holidays_client = BankHolidays(locale='en', use_cached_holidays=True)\n",
    "division = 'england-and-wales'\n",
    "holidays_list = bank_holidays_client.get_holidays(division=division)\n",
    "bank_holidays_df = pd.DataFrame(holidays_list).sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "# Convert date column to proper date type\n",
    "bank_holidays_df['date'] = pd.to_datetime(bank_holidays_df['date'], dayfirst=True).dt.date\n",
    "\n",
    "# Define Delta Lake table path\n",
    "delta_table_path = 'abfss://Data_Forge@onelake.dfs.fabric.microsoft.com/LH_core_datetime.Lakehouse/Tables/bank_holidays'\n",
    "\n",
    "# Storage options for authentication\n",
    "storage_options = {\n",
    "    \"bearer_token\": credentials.getToken('storage'),\n",
    "    \"use_fabric_endpoint\": \"true\",\n",
    "    \"allow_unsafe_rename\": \"true\"\n",
    "}\n",
    "\n",
    "# Write to Delta Lake\n",
    "write_deltalake(\n",
    "    delta_table_path,\n",
    "    bank_holidays_df,\n",
    "    mode='overwrite',\n",
    "    schema_mode='merge',\n",
    "    engine='rust',\n",
    "    storage_options=storage_options\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a453b-03c7-450c-8c46-4611cfa1dca1",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "from deltalake import DeltaTable\n",
    "\n",
    "# Define the mounted path to the Delta table\n",
    "delta_table_path = \"/lakehouse/default/Tables/shift_patten\"\n",
    "\n",
    "# Load the Delta table from the mounted path\n",
    "delta_table = DeltaTable(delta_table_path)\n",
    "\n",
    "# Retrieve the data as a PyArrow Dataset\n",
    "pyarrow_dataset = delta_table.to_pyarrow_dataset()\n",
    "\n",
    "# Convert the PyArrow Dataset to a Table\n",
    "pyarrow_table = pyarrow_dataset.to_table()\n",
    "\n",
    "# Convert the PyArrow Table to a Pandas DataFrame\n",
    "shift_pattern_df = pyarrow_table.to_pandas()\n",
    "\n",
    "# Display the DataFrame\n",
    "display(shift_pattern_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9d570c-8054-4889-8018-44a61b37492d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "from deltalake import DeltaTable\n",
    "\n",
    "# Define the mounted path to the Delta table\n",
    "delta_table_path = \"/lakehouse/default/Tables/dcc_school_holidays\"\n",
    "\n",
    "# Load the Delta table from the mounted path\n",
    "delta_table = DeltaTable(delta_table_path)\n",
    "\n",
    "# Retrieve the data as a PyArrow Dataset\n",
    "pyarrow_dataset = delta_table.to_pyarrow_dataset()\n",
    "\n",
    "# Convert the PyArrow Dataset to a Table\n",
    "pyarrow_table = pyarrow_dataset.to_table()\n",
    "\n",
    "# Convert the PyArrow Table to a Pandas DataFrame\n",
    "school_holidays_df = pyarrow_table.to_pandas()\n",
    "\n",
    "# Display the DataFrame\n",
    "display(school_holidays_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af83b7-763b-43f4-9162-f72a9ded5e54",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "display(bank_holidays_df)\n",
    "\n",
    "display(shift_pattern_df)\n",
    "\n",
    "display(school_holidays_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3093788b-7a0a-41d9-890f-710f5a36ae2e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define date range\n",
    "start_date = \"2000-04-01\"\n",
    "end_date = \"2035-12-31\"\n",
    "dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# Base DataFrame\n",
    "date_dimension_df = pd.DataFrame({'Date': dates})\n",
    "\n",
    "# Day-level info\n",
    "date_dimension_df[\"Day\"] = date_dimension_df[\"Date\"].dt.day\n",
    "date_dimension_df[\"DayOfWeek\"] = date_dimension_df[\"Date\"].dt.dayofweek  # Monday=0\n",
    "date_dimension_df[\"DayName_Short\"] = date_dimension_df[\"Date\"].dt.strftime('%a')\n",
    "date_dimension_df[\"DayName_Long\"] = date_dimension_df[\"Date\"].dt.strftime('%A')\n",
    "date_dimension_df[\"IsWeekend\"] = date_dimension_df[\"DayOfWeek\"].isin([5, 6])  # Saturday=5, Sunday=6\n",
    "date_dimension_df[\"DayOfYear\"] = date_dimension_df[\"Date\"].dt.dayofyear\n",
    "\n",
    "# Calendar (CY) info\n",
    "date_dimension_df[\"CY_Year\"] = date_dimension_df[\"Date\"].dt.year\n",
    "date_dimension_df[\"CY_Quarter\"] = \"Q\" + date_dimension_df[\"Date\"].dt.quarter.astype(str)\n",
    "date_dimension_df[\"CY_Month\"] = date_dimension_df[\"Date\"].dt.month\n",
    "date_dimension_df[\"MonthName_Short\"] = date_dimension_df[\"Date\"].dt.strftime('%b')\n",
    "date_dimension_df[\"MonthName_Long\"] = date_dimension_df[\"Date\"].dt.strftime('%B')\n",
    "date_dimension_df[\"CY_WeekOfYear\"] = date_dimension_df[\"Date\"].dt.isocalendar().week\n",
    "\n",
    "# Calendar period boundaries (dates only)\n",
    "date_dimension_df[\"StartOfMonth\"] = date_dimension_df[\"Date\"].values.astype('datetime64[M]').astype('datetime64[D]')\n",
    "date_dimension_df[\"EndOfMonth\"] = (date_dimension_df[\"StartOfMonth\"] + pd.offsets.MonthEnd(1)).dt.date\n",
    "date_dimension_df[\"StartOfWeek\"] = (date_dimension_df[\"Date\"] - pd.to_timedelta(date_dimension_df[\"DayOfWeek\"], unit='d')).dt.date\n",
    "date_dimension_df[\"EndOfWeek\"] = (pd.to_datetime(date_dimension_df[\"StartOfWeek\"]) + pd.Timedelta(days=6)).dt.date\n",
    "date_dimension_df[\"CY_StartOfQuarter\"] = date_dimension_df[\"Date\"].dt.to_period(\"Q\").apply(lambda p: p.start_time.date())\n",
    "date_dimension_df[\"CY_EndOfQuarter\"] = date_dimension_df[\"Date\"].dt.to_period(\"Q\").apply(lambda p: p.end_time.date())\n",
    "\n",
    "# Quarter start/end day of week (CY)\n",
    "date_dimension_df[\"CY_StartOfQuarter_DayOfWeek\"] = pd.to_datetime(date_dimension_df[\"CY_StartOfQuarter\"]).dt.dayofweek\n",
    "date_dimension_df[\"CY_EndOfQuarter_DayOfWeek\"] = pd.to_datetime(date_dimension_df[\"CY_EndOfQuarter\"]).dt.dayofweek\n",
    "\n",
    "# Composite calendar keys\n",
    "date_dimension_df[\"CY_YearMonth\"] = date_dimension_df[\"Date\"].dt.strftime(\"%Y/%m\")\n",
    "date_dimension_df[\"CY_YearQuarter\"] = date_dimension_df[\"CY_Year\"].astype(str) + \"/\" + date_dimension_df[\"CY_Quarter\"]\n",
    "\n",
    "# Fiscal (FS) info\n",
    "date_dimension_df[\"FS_Year\"] = date_dimension_df[\"Date\"].apply(lambda d: d.year if d.month >= 4 else d.year - 1)\n",
    "date_dimension_df[\"FS_Quarter\"] = date_dimension_df[\"Date\"].apply(\n",
    "    lambda d: \"Q\" + str((((((d.month - 4) % 12) + 1) - 1) // 3) + 1)\n",
    ")\n",
    "date_dimension_df[\"FS_Month\"] = date_dimension_df[\"Date\"].apply(lambda d: ((d.month - 4) % 12) + 1)\n",
    "\n",
    "# Fiscal Month Name Short\n",
    "fiscal_month_names = [\"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\", \"Jan\", \"Feb\", \"Mar\"]\n",
    "date_dimension_df[\"FS_MonthName_Short\"] = date_dimension_df[\"FS_Month\"].apply(lambda x: fiscal_month_names[x-1])\n",
    "\n",
    "# FS start of quarter helper function\n",
    "def start_of_fs_quarter(date):\n",
    "    fiscal_year = date.year if date.month >= 4 else date.year - 1\n",
    "    fiscal_month = ((date.month - 4) % 12) + 1\n",
    "    quarter_start_month = 4 + ((fiscal_month - 1) // 3) * 3\n",
    "    if quarter_start_month > 12:\n",
    "        fiscal_year += 1\n",
    "        quarter_start_month -= 12\n",
    "    return pd.Timestamp(fiscal_year, quarter_start_month, 1).date()\n",
    "\n",
    "date_dimension_df[\"FS_StartOfQuarter\"] = date_dimension_df[\"Date\"].apply(start_of_fs_quarter)\n",
    "date_dimension_df[\"FS_EndOfQuarter\"] = (pd.to_datetime(date_dimension_df[\"FS_StartOfQuarter\"]) + pd.offsets.QuarterEnd(startingMonth=3)).dt.date\n",
    "\n",
    "# Quarter start/end day of week (FS)\n",
    "date_dimension_df[\"FS_StartOfQuarter_DayOfWeek\"] = pd.to_datetime(date_dimension_df[\"FS_StartOfQuarter\"]).dt.dayofweek\n",
    "date_dimension_df[\"FS_EndOfQuarter_DayOfWeek\"] = pd.to_datetime(date_dimension_df[\"FS_EndOfQuarter\"]).dt.dayofweek\n",
    "\n",
    "# FS Week of Year (week 1 starts April 1)\n",
    "def fiscal_week_of_year(date):\n",
    "    fiscal_year_start = pd.Timestamp(date.year if date.month >= 4 else date.year - 1, 4, 1)\n",
    "    return ((date - fiscal_year_start).days // 7) + 1\n",
    "\n",
    "date_dimension_df[\"FS_WeekOfYear\"] = date_dimension_df[\"Date\"].apply(fiscal_week_of_year)\n",
    "\n",
    "# Composite FS keys\n",
    "date_dimension_df[\"FS_YearMonth\"] = date_dimension_df[\"FS_Year\"].astype(str) + \"/\" + date_dimension_df[\"FS_Month\"].apply(lambda m: f\"{m:02}\")\n",
    "date_dimension_df[\"FS_YearQuarter\"] = date_dimension_df[\"FS_Year\"].astype(str) + \"/\" + date_dimension_df[\"FS_Quarter\"].astype(str)\n",
    "date_dimension_df[\"FS_YearSpan\"] = date_dimension_df[\"FS_Year\"].astype(str) + \"/\" + (date_dimension_df[\"FS_Year\"] + 1).astype(str).str[-2:]\n",
    "\n",
    "# Days in month\n",
    "date_dimension_df[\"DaysInMonth\"] = date_dimension_df[\"Date\"].dt.days_in_month\n",
    "\n",
    "# Last Working Day of Month (Mon-Fri)\n",
    "def last_working_day(date):\n",
    "    last_day = date + pd.offsets.MonthEnd(0)\n",
    "    if last_day.weekday() == 5:  # Saturday\n",
    "        return last_day - pd.Timedelta(days=1)\n",
    "    elif last_day.weekday() == 6:  # Sunday\n",
    "        return last_day - pd.Timedelta(days=2)\n",
    "    else:\n",
    "        return last_day\n",
    "\n",
    "date_dimension_df[\"LastWorkingDayOfMonth\"] = date_dimension_df[\"Date\"].apply(last_working_day)\n",
    "\n",
    "# ISO calendar fields\n",
    "iso_calendar = date_dimension_df[\"Date\"].dt.isocalendar()\n",
    "date_dimension_df[\"ISO_Year\"] = iso_calendar.year\n",
    "date_dimension_df[\"ISO_WeekOfYear\"] = iso_calendar.week\n",
    "date_dimension_df[\"ISO_Weekday\"] = iso_calendar.day\n",
    "\n",
    "# ------------------------\n",
    "# Convert all date columns to date-only (no time)\n",
    "date_cols = [\n",
    "    \"Date\", \"StartOfMonth\", \"EndOfMonth\", \"StartOfWeek\", \"EndOfWeek\",\n",
    "    \"CY_StartOfQuarter\", \"CY_EndOfQuarter\", \"FS_StartOfQuarter\", \"FS_EndOfQuarter\",\n",
    "    \"LastWorkingDayOfMonth\"\n",
    "]\n",
    "for col in date_cols:\n",
    "    date_dimension_df[col] = pd.to_datetime(date_dimension_df[col]).dt.date\n",
    "\n",
    "# ------------ BANK HOLIDAYS JOIN ---------------\n",
    "# Assume bank_holidays_df is your DataFrame with columns 'date' and 'title'\n",
    "bank_holidays_df['date'] = pd.to_datetime(bank_holidays_df['date']).dt.date\n",
    "\n",
    "# Merge bank holidays onto date_dimension_df\n",
    "date_dimension_df = date_dimension_df.merge(\n",
    "    bank_holidays_df.rename(columns={'date': 'Date', 'title': 'BankHolidayName'}),\n",
    "    on='Date',\n",
    "    how='left'\n",
    ")\n",
    "date_dimension_df['IsBankHoliday'] = date_dimension_df['BankHolidayName'].notna()\n",
    "\n",
    "# ------------ SCHOOL HOLIDAYS JOIN ---------------\n",
    "# Assume school_holidays_df has columns 'closing_date', 'opening_date', and 'Holiday'\n",
    "school_holidays_df['closing_date'] = pd.to_datetime(school_holidays_df['closing_date']).dt.date\n",
    "school_holidays_df['opening_date'] = pd.to_datetime(school_holidays_df['opening_date']).dt.date\n",
    "\n",
    "# Function to check if a date is within any school holiday range\n",
    "def is_school_holiday(date, holidays_df):\n",
    "    return ((holidays_df['closing_date'] <= date) & (holidays_df['opening_date'] >= date)).any()\n",
    "\n",
    "# Function to get concatenated school holiday names for a date\n",
    "def get_school_holiday_names(date, holidays_df):\n",
    "    names = holidays_df.loc[\n",
    "        (holidays_df['closing_date'] <= date) & (holidays_df['opening_date'] >= date), 'Holiday'\n",
    "    ].tolist()\n",
    "    return ', '.join(names) if names else None\n",
    "\n",
    "# Apply these functions to the date dimension\n",
    "date_dimension_df['SchoolHolidayName'] = date_dimension_df['Date'].apply(lambda d: get_school_holiday_names(d, school_holidays_df))\n",
    "date_dimension_df['IsSchoolHoliday'] = date_dimension_df['Date'].apply(lambda d: is_school_holiday(d, school_holidays_df))\n",
    "\n",
    "# Final sort and reset index\n",
    "date_dimension_df = date_dimension_df.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "# Display or return your final date dimension DataFrame\n",
    "display(date_dimension_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce9d88f-07d0-479c-abd1-ac2206dbf8d7",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Ensure shift pattern is ordered by Rota (1–8)\n",
    "shift_pattern_df = shift_pattern_df.sort_values('Rota').reset_index(drop=True)\n",
    "\n",
    "# Step 2: Calculate the Rota_Day (1–8) based on 8-day cycle from 2000-01-01\n",
    "rota_start_date = pd.to_datetime(\"2000-01-01\").date()\n",
    "date_dimension_df[\"Rota_Day\"] = ((date_dimension_df[\"Date\"] - rota_start_date).apply(lambda x: x.days) % 8) + 1\n",
    "\n",
    "\n",
    "# Step 3: Merge the shift pattern data into the date dimension\n",
    "date_dimension_df = date_dimension_df.merge(\n",
    "    shift_pattern_df,\n",
    "    left_on=\"Rota_Day\",\n",
    "    right_on=\"Rota\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Optional: drop duplicate 'Rota' column if needed\n",
    "date_dimension_df = date_dimension_df.drop(columns=[\"Rota\"])\n",
    "\n",
    "# Reorder for clarity if desired\n",
    "# columns = [\"Date\", \"Rota_Day\", \"Pattern_BlueShift\", \"Pattern_GreenShift\", ...] + other date columns\n",
    "# date_dimension_df = date_dimension_df[columns]\n",
    "\n",
    "display(date_dimension_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b314d11-fde9-45b1-ae98-337481ad8fc1",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def map_shift_to_phase(shift_str):\n",
    "    shift_str = str(shift_str).lower()\n",
    "    if \"day\" in shift_str:\n",
    "        return 0\n",
    "    elif \"night\" in shift_str:\n",
    "        return 1\n",
    "    else:\n",
    "        # Rota or other = 2\n",
    "        return 2\n",
    "\n",
    "def compute_tour_counts_with_reset(df, pattern_cols):\n",
    "    df = df.copy()\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # Fiscal year starting April 1\n",
    "    df['Fiscal_Year'] = df['Date'].apply(lambda d: d.year if d.month >= 4 else d.year - 1)\n",
    "\n",
    "    df = df.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "    for col in pattern_cols:\n",
    "        fiscal_col = \"FS_\" + col.split(\"_\")[1].replace(\"Shift\", \"\") + \"_Tour_Count\"\n",
    "        global_col = fiscal_col.replace(\"FS_\", \"AL_Global_\")\n",
    "\n",
    "        df[fiscal_col] = 0\n",
    "        df[global_col] = 0\n",
    "\n",
    "        current_fiscal_year = None\n",
    "        fiscal_tour_index = 0\n",
    "        global_tour_index = 3\n",
    "        day_counter = 0\n",
    "        tour_active = False\n",
    "\n",
    "        fiscal_counts = []\n",
    "        global_counts = []\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            date = row[\"Date\"]\n",
    "            fy = row[\"Fiscal_Year\"]\n",
    "            phase = map_shift_to_phase(row[col])\n",
    "\n",
    "            if fy != current_fiscal_year:\n",
    "                # Reset fiscal counter\n",
    "                current_fiscal_year = fy\n",
    "                fiscal_tour_index = 0\n",
    "                day_counter = 0\n",
    "                tour_active = False\n",
    "\n",
    "            if not tour_active:\n",
    "                if phase == 0:\n",
    "                    tour_active = True\n",
    "                    fiscal_tour_index += 1\n",
    "                    global_tour_index += 1\n",
    "                    day_counter = 1\n",
    "            else:\n",
    "                day_counter += 1\n",
    "                if day_counter == 8:\n",
    "                    fiscal_tour_index += 1\n",
    "                    global_tour_index += 1\n",
    "                    day_counter = 0\n",
    "\n",
    "            fiscal_counts.append(fiscal_tour_index)\n",
    "            global_counts.append(global_tour_index)\n",
    "\n",
    "        df[fiscal_col] = fiscal_counts\n",
    "        df[global_col] = global_counts\n",
    "\n",
    "    df.drop(\"Fiscal_Year\", axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Usage\n",
    "pattern_columns = [\"Pattern_BlueShift\", \"Pattern_GreenShift\", \"Pattern_RedShift\", \"Pattern_WhiteShift\"]\n",
    "\n",
    "date_dimension_df = compute_tour_counts_with_reset(date_dimension_df, pattern_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc11a32-95e6-49f3-9e15-f847f70236bb",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "date_dimension_df.query(\"Date == '2026-04-01'\")[[\"Date\", \"AL_Global_Red_Tour_Count\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4de8a6c-6773-43b5-8556-5336ff867696",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Get count of days in each Red tour\n",
    "red_tour_sizes = (\n",
    "    date_dimension_df\n",
    "    .groupby([\"FS_Year\", \"FS_Red_Tour_Count\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"DayCount\")\n",
    ")\n",
    "\n",
    "# Filter only problematic ones (not equal to 8)\n",
    "problem_red_tours = red_tour_sizes[red_tour_sizes[\"DayCount\"] != 8]\n",
    "\n",
    "display(problem_red_tours)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af780dc-e1fa-4a55-a94f-a4bef4f2b40c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "display(date_dimension_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a000e23-fd66-4c62-bb57-7808ab09f6b8",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "for col in ['Date', 'StartOfMonth', 'LastWorkingDayOfMonth']:\n",
    "    date_dimension_df[col] = pd.to_datetime(date_dimension_df[col]).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939efa54-0586-4a55-b8c3-fdfa56158603",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_first_group_mapping_df(start_year=2010, years_ahead=45, years_back=11):\n",
    "    pattern = ['A', 'J', 'B', 'K', 'C', 'L', 'D', 'G', 'E', 'H', 'F', 'I']\n",
    "    current_year = datetime.now().year\n",
    "    end_year = current_year + years_ahead\n",
    "    start_year_back = start_year - years_back  # e.g. 2010 - 11 = 1999\n",
    "\n",
    "    # Combine years backward and forward into one list\n",
    "    years = list(range(start_year_back, start_year)) + list(range(start_year, end_year + 1))\n",
    "\n",
    "    data = [\n",
    "        {\"FS_Year\": year, \"First_Group\": pattern[(year - start_year) % len(pattern)]}\n",
    "        for year in years\n",
    "    ]\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Create the DataFrame with backwards extension to 1999\n",
    "first_group_df = generate_first_group_mapping_df()\n",
    "\n",
    "display(first_group_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6576634-494a-4580-9f48-78a57908ea49",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Define base and extras\n",
    "base_pattern = ['A', 'J', 'B', 'K', 'C', 'L', 'D', 'G', 'E', 'H', 'F', 'I']\n",
    "full_base = base_pattern * 3  # 36 total\n",
    "extras = ['Ex1', 'Ex2', 'Ex3', 'Ex4']\n",
    "\n",
    "# Map FS_Year -> pattern start index\n",
    "start_index_map = {\n",
    "    row['FS_Year']: base_pattern.index(row['First_Group'])\n",
    "    for _, row in first_group_df.iterrows()\n",
    "}\n",
    "\n",
    "# Function to return group for a tour count\n",
    "def get_group_letter_with_year(fs_year, tour_count):\n",
    "    if pd.isna(tour_count) or tour_count == 0:\n",
    "        return None\n",
    "\n",
    "    start_idx = start_index_map.get(fs_year, 0)\n",
    "    # Rotate the full 36-tour pattern\n",
    "    rotated_36 = full_base[start_idx:] + full_base[:start_idx]\n",
    "    full_shifted = rotated_36 + extras  # 40 total\n",
    "\n",
    "    tour_index = int(tour_count) - 1\n",
    "    if 0 <= tour_index < len(full_shifted):\n",
    "        return full_shifted[tour_index]\n",
    "    else:\n",
    "        return None  # Beyond 40 tours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36367c23-fbfe-433e-ab16-f576b0a55cbe",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Year-start pattern (defines who goes first each year)\n",
    "year_start_pattern = ['A', 'J', 'B', 'K', 'C', 'L', 'D', 'G', 'E', 'H', 'F', 'I']\n",
    "\n",
    "# Alphabetical order used inside year\n",
    "alphabetical_pattern = ['A','B','C','D','E','F','G','H','I','J','K','L']\n",
    "\n",
    "total_blocks = 46\n",
    "ex_insert_map = {\n",
    "    33: 'Ex1',\n",
    "    34: 'Ex2',\n",
    "    43: 'Ex3',\n",
    "    44: 'Ex4'\n",
    "}\n",
    "\n",
    "# Offsets relative to first index for the in-year pattern\n",
    "inside_year_offsets = [\n",
    "    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 10, 11, 11, 0, 0, 1, 1, 2, 2,\n",
    "    3, 4, 5, 6, 7, 8, 9, 10, 11, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 0\n",
    "]\n",
    "\n",
    "def get_first_group(fs_year, base_year=2010):\n",
    "    return year_start_pattern[(fs_year - base_year) % len(year_start_pattern)]\n",
    "\n",
    "def generate_leave_pattern(fs_year, base_year=2010):\n",
    "    first_group = get_first_group(fs_year, base_year)\n",
    "    first_index = alphabetical_pattern.index(first_group)\n",
    "\n",
    "    normal_blocks = [\n",
    "        alphabetical_pattern[(first_index + offset) % len(alphabetical_pattern)]\n",
    "        for offset in inside_year_offsets\n",
    "    ]\n",
    "\n",
    "    full_pattern = []\n",
    "    i_normal = 0\n",
    "    for i in range(total_blocks):\n",
    "        if i in ex_insert_map:\n",
    "            full_pattern.append(ex_insert_map[i])\n",
    "        else:\n",
    "            full_pattern.append(normal_blocks[i_normal])\n",
    "            i_normal += 1\n",
    "    return full_pattern\n",
    "\n",
    "def generate_annual_leave_df(start_year=2000, years_ahead=None, base_year=2010):\n",
    "    if years_ahead is None:\n",
    "        current_year = datetime.now().year\n",
    "        years_ahead = current_year + 45 - start_year\n",
    "\n",
    "    years = range(start_year, start_year + years_ahead + 1)\n",
    "    rows = []\n",
    "    global_block_index = 1  # ← Global continuous counter\n",
    "\n",
    "    for year in years:\n",
    "        pattern_for_year = generate_leave_pattern(year, base_year)\n",
    "        for idx, group in enumerate(pattern_for_year, start=1):\n",
    "            rows.append({\n",
    "                'FS_Year': year,\n",
    "                'Block_Index': idx,               # Resets yearly\n",
    "                'Global_Block_Index': global_block_index,  # Continuous\n",
    "                'Group': group\n",
    "            })\n",
    "            global_block_index += 1\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Run it\n",
    "annual_leave_schedule_df = generate_annual_leave_df(start_year=2000, base_year=2010)\n",
    "display(annual_leave_schedule_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346fb83d-22ac-4de6-ad2b-1c85933be4bb",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "testing_df = annual_leave_schedule_df\n",
    "\n",
    "display(testing_df[testing_df[\"FS_Year\"].isin([2024, 2025, 2026, 2027])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02734396-e04c-4043-b573-c88240d58718",
   "metadata": {
    "editable": false,
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Color mappings\n",
    "watch_colors = [\"White\", \"Red\", \"Green\", \"Blue\"]\n",
    "\n",
    "# Start with the base date dimension DataFrame\n",
    "joined_df = date_dimension_df.copy()\n",
    "\n",
    "for color in watch_colors:\n",
    "    # Temporary rename: Group → AL_<Color>_Block\n",
    "    tmp = (\n",
    "        annual_leave_schedule_df\n",
    "        .rename(columns={\"Group\": f\"AL_Block_{color}\"})\n",
    "        [[\"FS_Year\", \"Block_Index\", f\"AL_Block_{color}\"]]\n",
    "    )\n",
    "\n",
    "    # Join using FS_Year and the appropriate FS_<Color>_Tour_Count\n",
    "    joined_df = joined_df.merge(\n",
    "        tmp,\n",
    "        how=\"left\",\n",
    "        left_on=[\"FS_Year\", f\"FS_{color}_Tour_Count\"],\n",
    "        right_on=[\"FS_Year\", \"Block_Index\"]\n",
    "    ).drop(columns=[\"Block_Index\"])\n",
    "\n",
    "# Final result\n",
    "display(joined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd67f86-0988-4cce-af5c-ff212e475e91",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "use_global = True  # or False to use FS counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c57e7f-ef33-4b4a-81e6-26d85b2b85bf",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Color mappings\n",
    "watch_colors = [\"White\", \"Red\", \"Green\", \"Blue\"]\n",
    "\n",
    "# Start with the base date dimension DataFrame\n",
    "joined_df = date_dimension_df.copy()\n",
    "\n",
    "for color in watch_colors:\n",
    "    # Determine tour count column name\n",
    "    join_col = f\"AL_{'Global' if use_global else 'FS'}_{color}_Tour_Count\"\n",
    "    \n",
    "    # Determine right-side (schedule) join key\n",
    "    block_index_col = \"Global_Block_Index\" if use_global else \"Block_Index\"\n",
    "\n",
    "    # Prepare the AL schedule table\n",
    "    tmp = (\n",
    "        annual_leave_schedule_df\n",
    "        .rename(columns={\"Group\": f\"AL_Block_{color}\"})\n",
    "        [[block_index_col] + ([] if use_global else [\"FS_Year\"]) + [f\"AL_Block_{color}\"]]\n",
    "    )\n",
    "\n",
    "    # Determine join keys\n",
    "    left_keys = [join_col] if use_global else [\"FS_Year\", join_col]\n",
    "    right_keys = [block_index_col] if use_global else [\"FS_Year\", block_index_col]\n",
    "\n",
    "    # Merge\n",
    "    joined_df = joined_df.merge(\n",
    "        tmp,\n",
    "        how=\"left\",\n",
    "        left_on=left_keys,\n",
    "        right_on=right_keys\n",
    "    ).drop(columns=[block_index_col])\n",
    "\n",
    "# Final result\n",
    "display(joined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374bb53f-e5e9-4359-bbb9-ac0422f429e5",
   "metadata": {
    "editable": true,
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "run_control": {
     "frozen": false
    }
   },
   "outputs": [],
   "source": [
    "for col in ['Date', 'StartOfMonth', 'LastWorkingDayOfMonth']:\n",
    "    joined_df[col] = pd.to_datetime(joined_df[col]).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "table_path = '/lakehouse/default/Tables/Date_Table'\n",
    "\n",
    "if os.path.exists(table_path):\n",
    "    shutil.rmtree(table_path)  # WARNING: Deletes all files in the folder\n",
    "\n",
    "write_deltalake(\n",
    "    table_path,\n",
    "    joined_df,\n",
    "    mode='overwrite',\n",
    "    schema_mode='merge',\n",
    "    engine='rust',\n",
    "    storage_options=storage_options\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "d19bbe18-5517-47eb-8d82-3fb4f5b0f304",
    "default_lakehouse_name": "LH_core_datetime",
    "default_lakehouse_workspace_id": "ed71b21b-75f9-4f90-b327-aa6109317b9e",
    "known_lakehouses": [
     {
      "id": "d19bbe18-5517-47eb-8d82-3fb4f5b0f304"
     }
    ]
   }
  },
  "kernel_info": {
   "jupyter_kernel_name": "python3.11",
   "name": "jupyter"
  },
  "kernelspec": {
   "display_name": "Jupyter",
   "name": "jupyter"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "jupyter_python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
